{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP : Traitement du Signal\n",
    "### Objectif\n",
    "\n",
    "L'objectif de ce TP est de mesurer la vitesse du son en utilisant le matériel fourni.\n",
    "\n",
    "### Matériel\n",
    "\n",
    "- Haut-parleur\n",
    "- Deux microphones\n",
    "- Ordinateur avec Python et Jupyter Notebook installés\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. Comment peut-on mesurer la vitesse du son ?\n",
    "2. Comment isoler le signal émis par l'haut-parleur et comment peut-on minimiser les bruits captés par les microphones ?\n",
    "\n",
    "### Code\n",
    "\n",
    "Voici le code Python à utiliser pour générer les signaux et enregistrer le son :\n",
    "\n",
    "```\n",
    "# Importer les bibliothèques nécessaires\n",
    "# Gestion du son\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "# Bibliothèques pour analyse traitement du signal\n",
    "import scipy.io.wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Bibliothèques pour générer, acquérir les sons\n",
    "import traitesignfip\n",
    "\n",
    "\n",
    "traitesignfip.record_microphone(\"noise\") #Acquisition du son des microphones durant 5 secondes, l'haut-parleur émet le son passé en argument pendant 1 seconde\n",
    "\n",
    "rate, data = scipy.io.wavfile.read('enregistrement.wav')#Lecture du fichier où l'acquisition a été enregistrée \n",
    "\n",
    "data_right = data[:,1]\n",
    "data_left = data[:,0]\n",
    "\n",
    "#Ces deux lignes permettent de séparer les deux canaux (Left and Right) car chacun des 2 micros enregistre sur un canal différent. \n",
    "#Ainsi deux tableaux permettent de traiter les valeurs de chaque micro.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code python permettant de réaliser la mesure du son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#Bibliothèques pour générer, acquérir les sons\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraitesignfip\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m traitesignfip\u001b[39m.\u001b[39;49mrecord_microphone(\u001b[39m\"\u001b[39;49m\u001b[39mnoise\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m rate, data \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mwavfile\u001b[39m.\u001b[39mread(\u001b[39m'\u001b[39m\u001b[39menregistrement.wav\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/adhome/p/pm/pmisiuk/Bureau/TP-master/MesureDuSon.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m fs \u001b[39m=\u001b[39m \u001b[39m44100\u001b[39m \u001b[39m# fréquence d'échantillonage\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/TP-master/traitesignfip.py:43\u001b[0m, in \u001b[0;36mrecord_microphone\u001b[0;34m(signal_type)\u001b[0m\n\u001b[1;32m     41\u001b[0m sample_rate \u001b[39m=\u001b[39m \u001b[39m44100\u001b[39m  \u001b[39m# Fréquence d'échantillonnage en Hz\u001b[39;00m\n\u001b[1;32m     42\u001b[0m channels \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 43\u001b[0m t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39mint\u001b[39m(sample_rate),endpoint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m signal_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnoise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     zeros \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m3\u001b[39m\u001b[39m*\u001b[39msample_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "# Gestion du son\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "# Bibliothèques pour analyse traitement du signal\n",
    "import scipy.io.wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Bibliothèques pour générer, acquérir les sons\n",
    "import traitesignfip\n",
    "\n",
    "traitesignfip.record_microphone(\"noise\")\n",
    "\n",
    "rate, data = scipy.io.wavfile.read('enregistrement.wav')\n",
    "\n",
    "fs = 44100 # fréquence d'échantillonage\n",
    "N=len(data) #nombre d'échantillions \n",
    "n = np.arange(0,N)/fs   #on divise par la fréquence d'échantillonage pour etre mieux dans l'échelle \n",
    "\n",
    "\n",
    "distance=0.50\n",
    "\n",
    "data_right = data[:,1]\n",
    "data_left = data[:,0]\n",
    "\n",
    "#affichage du channel 1 \n",
    "plt.figure()\n",
    "plt.title(\"Right\")\n",
    "plt.plot(n,data_right)\n",
    "plt.figure()\n",
    "plt.title(\"Left\")\n",
    "plt.plot(n,data_left)\n",
    "\n",
    "# fc = 1000 # fréquence de coupure du filtre passe-bas\n",
    "# b, a = sp.signal.butter(4, fc / (fs / 2), 'low')\n",
    "# data_left_filtered = sp.signal.filtfilt(b, a, data_left)\n",
    "# data_right_filtered = sp.signal.filtfilt(b, a, data_right)\n",
    "\n",
    "\n",
    "corrLeft=np.correlate(data_left,traitesignfip.samples, mode='same')\n",
    "corrRight=np.correlate(data_right,traitesignfip.samples, mode='same')\n",
    "# Calcul de la corrélation croisée entre les deux signaux\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"CorrelLeft\")\n",
    "plt.plot(n,corrLeft)\n",
    "#signal X\n",
    "plt.figure()\n",
    "plt.title(\"CorrelRight\")\n",
    "plt.plot(n,corrRight)\n",
    "#signal X\n",
    "\n",
    "\n",
    "\n",
    "# Trouver l'indice du maximum de la corrélation\n",
    "max_index_Left = np.argmax(corrLeft)/fs\n",
    "max_index_Right = np.argmax(corrRight)/fs\n",
    "\n",
    "delta_t = delta = np.abs(max_index_Left - max_index_Right)\n",
    "\n",
    "print(\"Temps PIC Gauche : \"+str(max_index_Left))\n",
    "print(\"Temps PIC Droit : \"+str(max_index_Right))\n",
    "\n",
    "print(\"Delta : \"+str(delta_t))\n",
    "print(\"Vitesse : \"+str(distance/delta_t)+\" m/s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
